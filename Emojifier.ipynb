{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bf4b4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: emoji in c:\\users\\codexjoe\\appdata\\roaming\\python\\python39\\site-packages (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "253d2224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b4465218",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_emoji.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3780bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_emoji.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ee52b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "759dacba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop([2, 3], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a7a8c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1\n",
       "0           never talk to me again  3\n",
       "1  I am proud of your achievements  2\n",
       "2   It is the worst day in my life  3\n",
       "3                 Miss you so much  0\n",
       "4                     food is life  4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e8e2089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b4ec4391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want to eat\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he did not answer\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he got a very nice raise\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she got me a nice present\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ha ha ha it was so funny\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0  1\n",
       "0              I want to eat\\t  4\n",
       "1          he did not answer\\t  3\n",
       "2   he got a very nice raise\\t  2\n",
       "3  she got me a nice present\\t  2\n",
       "4   ha ha ha it was so funny\\t  2"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1155da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0]  = test_data[0].map(lambda x : x.replace('\\t',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "08efb264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want to eat</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he did not answer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he got a very nice raise</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she got me a nice present</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ha ha ha it was so funny</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0  1\n",
       "0              I want to eat  4\n",
       "1          he did not answer  3\n",
       "2   he got a very nice raise  2\n",
       "3  she got me a nice present  2\n",
       "4   ha ha ha it was so funny  2"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34a49c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4a6bc87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data[0]\n",
    "y_train1 = train_data[1]\n",
    "x_test = test_data[0]\n",
    "y_test1 = test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ef28d214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 0, 4, 1], dtype=int64)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f928cd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69a127ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \":red_heart:\",    \n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": ':smiling_face_with_smiling_eyes:',\n",
    "                    \"3\": \":disappointed_face:\",\n",
    "                    \"4\": \":fork_and_knife:\"}\n",
    "\n",
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dictionary[str(label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "974dd110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love my dad ❤️\n"
     ]
    }
   ],
   "source": [
    "print(x_train[100], label_to_emoji(y_train[100])) # Testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5d91737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxWord = len(max(x_train, key= len).split()) #key is the number of iterations\n",
    "maxWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9e5d28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting targets to one-hot encoding\n",
    "y_train = pd.get_dummies(y_train1)\n",
    "y_test = pd.get_dummies(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3f4873dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('glove.6B.100d.txt', encoding=\"utf8\") as file:\n",
    "# #     file.readline()\n",
    "#     words = set()        # ensures unique values\n",
    "#     word_to_vec_map = {}  # this will be a dictionary mapping words to their vectors\n",
    "#     for l in file:\n",
    "#         line = l.strip().split()\n",
    "#         curr_word = line[0]\n",
    "#         words.add(curr_word)\n",
    "#         word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "#     i = 1\n",
    "#     words_to_index = {}   # dictionary mapping words to their index in the dictionary\n",
    "#     index_to_words = {}   # dictionary mapping index to the word in the dictionary\n",
    "#     for w in sorted(words):\n",
    "#         words_to_index[w] = i\n",
    "#         index_to_words[i] = w\n",
    "#         i = i + 1\n",
    "            \n",
    "    \n",
    "        \n",
    "#     print(word_to_vec_map) # Remove character from each line and split\n",
    "#         curr_word = line[0] # Assign first index of the splited line\n",
    "#         words.add(curr_word) # Add the first index to the empty set()\n",
    "#         word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6adadbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226278\n"
     ]
    }
   ],
   "source": [
    "# # print(word_to_vec_map.get('the'))\n",
    "# print(words_to_index['love'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0876733b",
   "metadata": {},
   "source": [
    "### Global Vectors for Word Representation\n",
    "GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cbbe4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be using 100 d word vectors\n",
    "\n",
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, encoding=\"utf8\") as f: # I used encoding cos reading the file was returning error\n",
    "        \n",
    "        words = set()         # ensures unique values\n",
    "        word_to_vec_map = {}  # this will be a dictionary mapping words to their vectors\n",
    "        for line in f:\n",
    "            line = line.strip().split() # Remove character from the begining and ending of each line and spliting each item by spaces\n",
    "            curr_word = line[0] # Assign first index of the splited line\n",
    "            words.add(curr_word) # Add the first index to the empty set()\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64) # Form a dictionary using the first index as key and others as value\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}   # dictionary mapping words to their index in the dictionary\n",
    "        index_to_words = {}   # dictionary mapping index to the word in the dictionary\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n",
    "\n",
    "words_to_index, index_to_words, word_to_vec_map = read_glove_vecs('glove.6B.100d.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c18ee2f",
   "metadata": {},
   "source": [
    "### We now converts each array of sentences into an array of indices with a dictionary containing the each word mapped to its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "112d4216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_indices = np.zeros((x_train.shape[0], 10))\n",
    "\n",
    "\n",
    "\n",
    "# for items in range(x_train.shape[0]):                               \n",
    "        \n",
    "#         # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
    "#         sentence_words = x_train[items].lower().split() # We have converted each sentence to lowercase and tokenized\n",
    "# # print(sentence_words)\n",
    "# # print(x_train[131])\n",
    "        \n",
    "#         j = 0\n",
    "        \n",
    "#         # Loop over the words of sentence_words\n",
    "#         for w in sentence_words:\n",
    "#             X_indices[i, j] = words_to_index[w]\n",
    "#             j = j+1  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "64548b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_indices[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "72cfc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    " \n",
    "    m = X.shape[0]                                  \n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    \n",
    "    for i in range(m):                               \n",
    "        \n",
    "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
    "        sentence_words = X[i].lower().split()\n",
    "        \n",
    "        j = 0\n",
    "        \n",
    "        # Loop over the words of sentence_words\n",
    "        for w in sentence_words:\n",
    "            X_indices[i, j] = words_to_index[w]\n",
    "            j = j+1  \n",
    "    \n",
    "    return X_indices\n",
    "\n",
    "X_train_indices = sentences_to_indices(x_train, words_to_index, maxWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f38312a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1               # +1 for Keras  \n",
    "    emb_dim = 100                                     # dimensionality of your GloVe word vectors\n",
    "    \n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))      # Initialization with zeros\n",
    "    \n",
    "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "\n",
    "    # Define Keras embedding layer with the correct output/input sizes\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    \n",
    "    # Build the embedding layer\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e266c0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 7s 24ms/step - loss: 1.5942 - accuracy: 0.2879 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 1.5595 - accuracy: 0.3030 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 1.5526 - accuracy: 0.3258 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 1.5279 - accuracy: 0.3258 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 1.4713 - accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 1.4002 - accuracy: 0.5076 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 1.3269 - accuracy: 0.6061 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 1.3098 - accuracy: 0.6061 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 1.1902 - accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 1.1637 - accuracy: 0.7424 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 1.1627 - accuracy: 0.7424 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 1.1153 - accuracy: 0.8258 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 1.0592 - accuracy: 0.8561 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 1.0640 - accuracy: 0.8636 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 1.0292 - accuracy: 0.9015 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 1.0225 - accuracy: 0.8788 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.9983 - accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.9949 - accuracy: 0.9242 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.9867 - accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.9786 - accuracy: 0.9318 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 1.0466 - accuracy: 0.8561 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 1.0091 - accuracy: 0.8864 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.0484 - accuracy: 0.8485\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 1.0484 - accuracy: 0.8485 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 1.0944 - accuracy: 0.8030 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 1.0360 - accuracy: 0.8636 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.9764 - accuracy: 0.9318 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.9844 - accuracy: 0.9242 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.9655 - accuracy: 0.9470 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.9651 - accuracy: 0.9470 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.9588 - accuracy: 0.9470 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.9980 - accuracy: 0.9091 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.9616 - accuracy: 0.9470 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 1.0010 - accuracy: 0.8929\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 1.0099 - accuracy: 0.8864 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.9786 - accuracy: 0.9318 - lr: 2.5000e-04\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.9582 - accuracy: 0.9470 - lr: 2.5000e-04\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.9449 - accuracy: 0.9621 - lr: 2.5000e-04\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.9433 - accuracy: 0.9697 - lr: 2.5000e-04\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.9437 - accuracy: 0.9697 - lr: 2.5000e-04\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.9417 - accuracy: 0.9697 - lr: 2.5000e-04\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.9368 - accuracy: 0.9697 - lr: 2.5000e-04\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.9428 - accuracy: 0.9621 - lr: 2.5000e-04\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.9401 - accuracy: 0.9697 - lr: 2.5000e-04\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.9369 - accuracy: 0.9697\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.9369 - accuracy: 0.9697 - lr: 2.5000e-04\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.9367 - accuracy: 0.9697 - lr: 1.2500e-04\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.9332 - accuracy: 0.9697 - lr: 1.2500e-04\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.9319 - accuracy: 0.9773 - lr: 1.2500e-04\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.9298 - accuracy: 0.9773 - lr: 1.2500e-04\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.9297 - accuracy: 0.9773 - lr: 1.2500e-04\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.9301 - accuracy: 0.9773 - lr: 1.2500e-04\n",
      "Epoch 50/50\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.9305 - accuracy: 0.9766\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.9298 - accuracy: 0.9773 - lr: 1.2500e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e503964a30>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Emojify(input_shape, word_to_vec_map, word_to_index):\n",
    "    sentence_indices = Input(shape=input_shape, dtype='int32')\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    \n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(5, activation='softmax')(X)\n",
    "    X = Activation('softmax')(X)    \n",
    "    \n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "    \n",
    "    return model\n",
    "\n",
    "emojifier = Emojify((maxWord,), word_to_vec_map, words_to_index)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, min_lr=0.00001, verbose=1)\n",
    "emojifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "emojifier.fit(X_train_indices, y_train, epochs = 50, batch_size = 16, shuffle=True, \n",
    "                               callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4d4510c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 12ms/step - loss: 1.0320 - accuracy: 0.8750\n",
      "\n",
      "Test accuracy =  0.875\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(x_test, words_to_index, maxWord)\n",
    "\n",
    "loss, acc = emojifier.evaluate(X_test_indices, y_test)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "00cf03a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 14ms/step\n",
      "[0.14889567 0.14891921 0.14887488 0.14887415 0.40443614]\n",
      "Expected emoji:😊 prediction: he got a very nice raise❤️\n",
      "Expected emoji:😊 prediction: she got me a nice present❤️\n",
      "Expected emoji:😞 prediction: work is horrible😊\n",
      "Expected emoji:😊 prediction: you brighten my day😞\n",
      "Expected emoji:😞 prediction: she is a bully❤️\n",
      "Expected emoji:😊 prediction: will you be my valentine❤️\n",
      "Expected emoji:😞 prediction: go away⚾\n"
     ]
    }
   ],
   "source": [
    "pred = emojifier.predict(X_test_indices)\n",
    "print(pred[0])\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    \n",
    "    num = np.argmax(pred[i])\n",
    "    if(num != y_test1[i]):\n",
    "        print('Expected emoji:'+ label_to_emoji(y_test1[i]) + ' prediction: '+ x_test[i] + label_to_emoji(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6a80309c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected emoji:🍴 prediction: I want to eat🍴\n",
      "Expected emoji:😞 prediction: he did not answer😞\n",
      "Expected emoji:😊 prediction: he got a very nice raise❤️\n",
      "Expected emoji:😊 prediction: she got me a nice present❤️\n",
      "Expected emoji:😊 prediction: ha ha ha it was so funny😊\n",
      "Expected emoji:😊 prediction: he is a good friend😊\n",
      "Expected emoji:😞 prediction: I am upset😞\n",
      "Expected emoji:😊 prediction: We had such a lovely dinner tonight😊\n",
      "Expected emoji:🍴 prediction: where is the food🍴\n",
      "Expected emoji:😊 prediction: Stop making this joke ha ha ha😊\n",
      "Expected emoji:⚾ prediction: where is the ball⚾\n",
      "Expected emoji:😞 prediction: work is hard😞\n",
      "Expected emoji:😞 prediction: This girl is messing with me😞\n",
      "Expected emoji:😞 prediction: are you serious😞\n",
      "Expected emoji:⚾ prediction: Let us go play baseball⚾\n",
      "Expected emoji:😞 prediction: This stupid grader is not working 😞\n",
      "Expected emoji:😞 prediction: work is horrible😊\n",
      "Expected emoji:😊 prediction: Congratulation for having a baby😊\n",
      "Expected emoji:😞 prediction: stop pissing me off😞\n",
      "Expected emoji:🍴 prediction: any suggestions for dinner🍴\n",
      "Expected emoji:❤️ prediction: I love taking breaks❤️\n",
      "Expected emoji:😊 prediction: you brighten my day😞\n",
      "Expected emoji:🍴 prediction: I boiled rice🍴\n",
      "Expected emoji:😞 prediction: she is a bully❤️\n",
      "Expected emoji:😞 prediction: Why are you feeling bad😞\n",
      "Expected emoji:😞 prediction: I am upset😞\n",
      "Expected emoji:⚾ prediction: give me the ball⚾\n",
      "Expected emoji:❤️ prediction: My grandmother is the love of my life❤️\n",
      "Expected emoji:⚾ prediction: enjoy your game⚾\n",
      "Expected emoji:😊 prediction: valentine day is near😊\n",
      "Expected emoji:❤️ prediction: I miss you so much❤️\n",
      "Expected emoji:⚾ prediction: throw the ball⚾\n",
      "Expected emoji:😞 prediction: My life is so boring😞\n",
      "Expected emoji:😊 prediction: she said yes😊\n",
      "Expected emoji:😊 prediction: will you be my valentine❤️\n",
      "Expected emoji:⚾ prediction: he can pitch really well⚾\n",
      "Expected emoji:😊 prediction: dance with me😊\n",
      "Expected emoji:🍴 prediction: I am hungry🍴\n",
      "Expected emoji:🍴 prediction: See you at the restaurant🍴\n",
      "Expected emoji:😊 prediction: I like to laugh😊\n",
      "Expected emoji:⚾ prediction: I will  run⚾\n",
      "Expected emoji:❤️ prediction: I like your jacket ❤️\n",
      "Expected emoji:❤️ prediction: i miss her❤️\n",
      "Expected emoji:⚾ prediction: what is your favorite baseball game⚾\n",
      "Expected emoji:😊 prediction: Good job😊\n",
      "Expected emoji:❤️ prediction: I love you to the stars and back❤️\n",
      "Expected emoji:😊 prediction: What you did was awesome😊\n",
      "Expected emoji:😊 prediction: ha ha ha lol😊\n",
      "Expected emoji:😞 prediction: I do not want to joke😞\n",
      "Expected emoji:😞 prediction: go away⚾\n",
      "Expected emoji:😞 prediction: yesterday we lost again😞\n",
      "Expected emoji:❤️ prediction: family is all I have❤️\n",
      "Expected emoji:😞 prediction: you are failing this exercise😞\n",
      "Expected emoji:😊 prediction: Good joke😊\n",
      "Expected emoji:😊 prediction: You deserve this nice prize😊\n",
      "Expected emoji:🍴 prediction: I did not have breakfast 🍴\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(x_test)):\n",
    "      \n",
    "    num = np.argmax(pred[i])\n",
    "    \n",
    "    print('Expected emoji:'+ label_to_emoji(y_test1[i]) + ' prediction: '+ x_test[i] + label_to_emoji(num))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6cf247fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "16135f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# container = open('emoji.pickle', 'wb')\n",
    "# pickle.dump(emojifier, container)\n",
    "# container.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "df59ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# container_opener = open('emoji.pickle', 'rb')\n",
    "# emojifier = pickle.load(container_opener)\n",
    "# container_opener.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5418ff6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
